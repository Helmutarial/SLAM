"""
Script to visualize the accumulated 2D plan of all point clouds generated by SLAM.
Merges all clouds saved in cloud_points and projects the points to the X-Y plane.
"""

import os
import time
import numpy as np
import matplotlib.pyplot as plt
import open3d as o3d
import json
from collaborative_slam.utils.file_utils import select_video_file
from collaborative_slam.utils.video_utils.extract_frames import extract_frames
from collaborative_slam.utils.pointcloud_utils import load_point_clouds
from collaborative_slam.utils.pointcloud_utils.accumulation import merge_point_clouds
from collaborative_slam.utils.pointcloud_utils.preprocessing import filter_isolated_points, filter_points_by_percentile
from collaborative_slam.utils.yolo_utils.detection_clustering_utils import cluster_detections_by_class
from collaborative_slam.utils.trayectory_utils.trajectory_filtering import load_camera_trajectory

# Folder where point clouds are saved (adjust if needed)
CLOUD_POINTS_FOLDER = os.path.join(
    os.path.dirname(__file__), '..', 'results', 'VIDEO1', 'cloud_points'
)

def main():
    min_confidence = 0.5  # Confidence threshold
    start_total = time.time()
    video_path = select_video_file()
    if not video_path:
        print('No video selected.')
        return
    folder_name = os.path.basename(os.path.dirname(video_path))
    results_dir = os.path.join(os.path.dirname(__file__), '..', 'results', folder_name)
    frames_dir = os.path.join(results_dir, 'detections', 'frames')
    cloud_dir = os.path.join(results_dir, 'cloud_points')
    poses_path = os.path.join(results_dir, 'poses.json')
    detections_3d_path = os.path.join(results_dir, 'detections_3d.json')

    # Extract frames if not present
    if not os.path.exists(frames_dir) or not os.listdir(frames_dir):
        print('Extracting frames...')
        t0 = time.time()
        extract_frames(video_path, frames_dir, every_n=30, ext='jpg')
        print(f"Frames extracted in {time.time() - t0:.2f} s")

    # Load projected detections to 3D (if exist)
    detections_3d = []
    poses = []
    if os.path.exists(detections_3d_path):
        with open(detections_3d_path, 'r') as f:
            detections_3d = json.load(f)
        print('Matching video frame (detection) <-> pose frame:')
        for i, det in enumerate(detections_3d):
            frame_video = det.get('frame', i)
            frame_pose = det.get('pose', None)
            print(f'Detection {i}: frame_video={frame_video} <-> pose frame={frame_pose}')

    # Class colors
    class_colors = {
        'bed': 'purple',
        'refrigerator': 'cyan',
        'tv': 'orange',
        'bottle': 'green',
        'book': 'brown',
        'laptop': 'red',
        'cell phone': 'yellow',
        'sofa': 'blue',
        'chair': 'magenta',
        'table': 'lime',
        # Add more if needed
    }
    wall_lines = []

    print(f"Loading point clouds from: {CLOUD_POINTS_FOLDER}")
    t0 = time.time()
    clouds, files = load_point_clouds(CLOUD_POINTS_FOLDER)
    print(f"Loaded point clouds in {time.time() - t0:.2f} s")
    if not clouds:
        print("No point clouds found.")
        return
    print(f"Merging {len(clouds)} clouds...")
    t0 = time.time()
    merged_cloud = merge_point_clouds(clouds)
    print(f"Clouds merged in {time.time() - t0:.2f} s")
    points = np.asarray(merged_cloud.points)
    if points.size == 0:
        print("Merged cloud is empty.")
        return
    # Project to X-Y plane and get Z
    points_xy = points[:, :2]
    points_z = points[:, 2]

    # Filter: limit X/Y range to center visualization
    filtered_points, filtered_z = filter_points_by_percentile(points_xy, points_z, x_percentile=[2,98], y_percentile=[2,98])

    # Noise filtering: remove isolated points
    t0 = time.time()
    clean_points, clean_z = filter_isolated_points(filtered_points, filtered_z, percentile=90, n_neighbors=6)
    print(f"Noise filtering done in {time.time() - t0:.2f} s")

    # Load and plot camera trajectory
    trajectory = load_camera_trajectory(poses_path)

    # Visualization: color by height (Z)
    import matplotlib.animation as animation
    t0 = time.time()
    fig, ax = plt.subplots(figsize=(10, 8))
    # Background points in light gray
    scatter = ax.scatter(clean_points[:, 0], clean_points[:, 1], s=2, c='gray', alpha=0.2, label='Point cloud')

    # Draw clustered detections by class
    if detections_3d:
        drawn_classes = set()
        count_drawn = 0
        clustered = cluster_detections_by_class(detections_3d, min_confidence=min_confidence, eps=1.2)
        for class_name, centroids in clustered.items():
            color = class_colors.get(class_name, 'red')
            for i, centroid in enumerate(centroids):
                ax.scatter(centroid[0], centroid[1], s=220, c=color, marker='*', edgecolors='black', linewidths=2, label=f'{class_name} (clustered)' if class_name not in drawn_classes else None)
                drawn_classes.add(class_name)
                count_drawn += 1
        print(f"Plotted {count_drawn} clustered detections by class with valid closest_point and confidence >= {min_confidence}.")

    # Camera trajectory animation
    if trajectory is not None and trajectory.size > 0:
        line, = ax.plot([], [], c='orange', lw=2, label='Camera trajectory')
        start = ax.scatter(trajectory[0, 0], trajectory[0, 1], color='green', s=80, label='Start')
        end = ax.scatter(trajectory[-1, 0], trajectory[-1, 1], color='red', s=80, label='End')
        def update(num):
            line.set_data(trajectory[:num, 0], trajectory[:num, 1])
            return line,
        ani = animation.FuncAnimation(fig, update, frames=len(trajectory), interval=60, blit=True, repeat=False)
        # Direction arrows (only at the end to avoid clutter)
        for i in range(0, len(trajectory)-1, max(1, len(trajectory)//20)):
            ax.arrow(trajectory[i, 0], trajectory[i, 1],
                    trajectory[i+1, 0] - trajectory[i, 0],
                    trajectory[i+1, 1] - trajectory[i, 1],
                    shape='full', lw=0, length_includes_head=True,
                    head_width=0.15, head_length=0.3, color='orange', alpha=0.7)
    # Draw detected walls (lines above points)
    for i, (x_range, y_range) in enumerate(wall_lines):
        if i == 0:
            ax.plot(x_range, y_range, c='blue', lw=4, alpha=0.95, label='Detected wall')
        else:
            ax.plot(x_range, y_range, c='blue', lw=4, alpha=0.95)
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_title('Accumulated 2D plan of point clouds + trajectory + walls + floor + detections')
    ax.axis('equal')
    ax.legend()
    ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.5)
    ax.set_facecolor('#f5f5f5')
    print(f"Visualization ready in {time.time() - t0:.2f} s")
    print(f"Total execution time: {time.time() - start_total:.2f} s")
    try:
        plt.show()
    finally:
        plt.close(fig)

if __name__ == "__main__":
    main()
